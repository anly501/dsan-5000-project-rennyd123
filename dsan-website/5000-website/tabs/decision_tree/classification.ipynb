{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "\n",
    "Classification decision trees are a great tool for helping you figure out information about a topic. Let's use the game 20 questions as an example. Say I ask you to guess what food I am thinking of. The food I've selected is gummy worms. We can use a series of yes or no questions to figure out what I've selected. You could ask if it is a healthy food, to which my answer would be no. You could ask if it was protein, I'd say no. You could ask if it was a carb, I'd say yes. You could ask if it was sweet, I'd say yes. You could ask if there is dairy in it, I'd say no. You can ask if it was a candy, I'd say yes. And so on until you finally ask if I selected gummy worms, to which I'd say yes. \n",
    "\n",
    "The appeal of decision trees is their ability to make the identification process very simple. Each question you ask helps to narrow down the number of possibilities. We can think of it as a visual flowchart that categorizes items based on their features. Going back to our previous example, we can classify foods based on their flavour profile or nutritional category. As we ask more questions, we will eventually get to our gummy worms. \n",
    "\n",
    "Making an effective decision tree involves initially posing questions that will reveal the most amount of information about the object's group. We want to figure out distinctive information as fast as possible, so we can distinguish between the groups. Decision trees have applications in many different fields, ranging from sorting out spam emails to diagnosing medical conditions. They are a tool that streamlines intricate decision-making by breaking it down into a sequence of straightforward choices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Class distribution\n",
    "Provide code to compute the distribution of class labels in your dataset. Comment on the results and what effect it might have on the classification algorithm results.\n",
    "## Baseline model for comparison\n",
    "As a baseline comparison, run a random classifier on your data and output accuracy, precision, and recall values.\n",
    "NOTE: Most of this code is already included in the shared/codes/random_classifier\n",
    "The provided code does a UNIFORM random number generation. Optionally, you can modify the random number generation process so that the random numbers are sampled based on the distribution of labels in your dataset. This will result in a more accurate random classifier.\n",
    "Comment on the results\n",
    "## Feature selection (optional)\n",
    "You can repeat this with your tree-algorithm, but if you already have an optimal feature set from a previous assignment, then you can stick with that one.\n",
    "There are many ways to “pre-process” data to make it more suitable for analysis.\n",
    "Make sure to document what you are doing and why you did what you did.\n",
    "Model tuning: Carry out, document, and visualize a hyper-parameter tuning protocol. Attempt to find the set of hyper parameters that result int the optimal model (i.e. lowest validation error without overfitting, validation and training error should be similar)\n",
    "## Final results\n",
    "Report, discuss, and visualize the results of the final optimally-fit model. For example, final training & validation errors, confusion matrices (values and plots), plots of the decision tree, etc. Comment on the quality of fit, why it might be good or bad, and what might be done to improve it.\n",
    "## Conclusions:\n",
    "Create two or more paragraphs, more is fine, that discuss in a NON-TECHNICAL way what was discovered, why it was important, things that went wrong, possible future directions, and what it all means for a general audience.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
